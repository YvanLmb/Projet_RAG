# Projet RAG : Recherche et G√©n√©ration (RAG) avanc√©e sur le dataset FQuAD

## üìö Description
Ce projet est une impl√©mentation d'un mod√®le de **Recherche et G√©n√©ration (RAG)** qui teste et compare diff√©rentes m√©thodes avanc√©es d'approches RAG sur le dataset fran√ßais **FQuAD**. L'objectif principal est d'√©valuer des techniques vari√©es de traitement, d'interrogation et de g√©n√©ration sur des questions-r√©ponses bas√©es sur des documents en fran√ßais.

---

## üöÄ Objectifs du Projet
1. **√âvaluer les approches avanc√©es de RAG** :
   - Comparer diff√©rentes m√©thodes, incluant le BM25, la recherche dense avec embeddings g√©n√©r√©s par **Sentence Transformers**, et des recherches hybrides.
   - Int√©grer des techniques avanc√©es de d√©coupage de texte (chunking).
2. **Explorer des configurations de mod√®les** :
   - Tester l'impact des configurations de temp√©rature sur la g√©n√©ration de r√©ponses.
   - Utiliser des mod√®les instructifs comme **Mistral-7B** pour la g√©n√©ration.
3. **Utilisation du dataset FQuAD** :
   - Le dataset FQuAD est une version fran√ßaise de SQuAD (Stanford Question Answering Dataset).
   - Il contient des paires question-r√©ponse bas√©es sur des contextes extraits de Wikip√©dia.
   - Objectif : R√©pondre √† des questions en exploitant des passages contextuels du dataset.

---

## üõ†Ô∏è M√©thodologie
### 1. Pr√©traitement des donn√©es
- Extraction et d√©coupage des contextes en chunks pour une gestion optimale.
- Indexation des donn√©es pour la recherche (BM25, dense avec embeddings, hybride).

### 2. M√©thodes explor√©es
- **No Processing** : Pas de d√©coupage pr√©alable, interrogation directe.
- **Early Chunking** : D√©coupage avant l'interrogation, avec analyse de chaque chunk.
- **Hybrid Search** : Combinaison pond√©r√©e des recherches BM25 et dense (embeddings Sentence Transformers).
- **Late Chunking** : D√©coupage apr√®s une recherche initiale.

### 3. G√©n√©ration d'Embeddings
- Les embeddings des textes ont √©t√© g√©n√©r√©s √† l'aide de **Sentence Transformers** ([HuggingFace SentenceTransformers](https://www.sbert.net/)).
- Mod√®le utilis√© : `sentence-transformers/all-MiniLM-L6-v2`, adapt√© pour des t√¢ches de recherche dense et de similarit√©.

### 4. √âvaluation des r√©sultats
- Comparaison des m√©thodes avec les m√©triques suivantes :
  - **Exact Match (EM)** et **F1 Score**
  - **BERTScore**
  - **ROUGE-1, ROUGE-2, ROUGE-L**
  - **BLEU**



## üîß Technologies Utilis√©es
- **Langages** : Python
- **Frameworks et librairies** :
  - LangChain pour le traitement des documents.
  - PyTorch et Transformers pour la gestion des mod√®les.
  - **Sentence Transformers** pour la g√©n√©ration d'embeddings.
  - BM25Okapi et FAISS pour la recherche.
  - Evaluation avec **BERTScore**, **ROUGE**, et **BLEU**.
- **Dataset** : FQuAD
- **Mod√®le** :
  - G√©n√©ration de r√©ponses : [Mistral-7B-Instruct-v0.1](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1)
  - Embeddings : [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)

---


---

## ü§ù Contributeurs
- **YvanLmb** : Cr√©ateur principal

---
